{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Merged_all_states_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5432, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>headline</th>\n",
       "      <th>detail_id</th>\n",
       "      <th>new_link</th>\n",
       "      <th>Case Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Icici Lombardf General Insurance Co Ltd vs Mon...</td>\n",
       "      <td>thus,\\nhelped him in getting acquittal. \\n...</td>\n",
       "      <td>/docfragment/78128413/?formInput=insurance%20f...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/78128413//</td>\n",
       "      <td>Take notes as you read a judgment using our  V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Moni Devi And Ors vs Hemant Bhardwaj And Anr o...</td>\n",
       "      <td>thus,\\nhelped him in getting acquittal. \\n...</td>\n",
       "      <td>/docfragment/19875390/?formInput=insurance%20f...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/19875390//</td>\n",
       "      <td>Take notes as you read a judgment using our  V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arman vs State Of Haryana on 27 August, 2024</td>\n",
       "      <td>attention     towards         the        i...</td>\n",
       "      <td>/docfragment/189088157/?formInput=insurance%20...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/189088157//</td>\n",
       "      <td>Take notes as you read a judgment using our  V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dashrath Tanwar vs Life Insurance Corporation ...</td>\n",
       "      <td>extracted from\\n\\nCWP-12070-2018 titled as...</td>\n",
       "      <td>/docfragment/52555161/?formInput=insurance%20f...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/52555161//</td>\n",
       "      <td>Take notes as you read a judgment using our  V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Kailash Kumar Shoree vs Ut Chandigarh on 14 Au...</td>\n",
       "      <td>forging the signatures of Late Smt.\\n     ...</td>\n",
       "      <td>/docfragment/139103740/?formInput=insurance%20...</td>\n",
       "      <td>https://indiankanoon.org/docfragment/139103740//</td>\n",
       "      <td>Take notes as you read a judgment using our  V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Icici Lombardf General Insurance Co Ltd vs Mon...   \n",
       "1           1  Moni Devi And Ors vs Hemant Bhardwaj And Anr o...   \n",
       "2           2       Arman vs State Of Haryana on 27 August, 2024   \n",
       "3           3  Dashrath Tanwar vs Life Insurance Corporation ...   \n",
       "4           4  Kailash Kumar Shoree vs Ut Chandigarh on 14 Au...   \n",
       "\n",
       "                                            headline  \\\n",
       "0      thus,\\nhelped him in getting acquittal. \\n...   \n",
       "1      thus,\\nhelped him in getting acquittal. \\n...   \n",
       "2      attention     towards         the        i...   \n",
       "3      extracted from\\n\\nCWP-12070-2018 titled as...   \n",
       "4      forging the signatures of Late Smt.\\n     ...   \n",
       "\n",
       "                                           detail_id  \\\n",
       "0  /docfragment/78128413/?formInput=insurance%20f...   \n",
       "1  /docfragment/19875390/?formInput=insurance%20f...   \n",
       "2  /docfragment/189088157/?formInput=insurance%20...   \n",
       "3  /docfragment/52555161/?formInput=insurance%20f...   \n",
       "4  /docfragment/139103740/?formInput=insurance%20...   \n",
       "\n",
       "                                           new_link  \\\n",
       "0   https://indiankanoon.org/docfragment/78128413//   \n",
       "1   https://indiankanoon.org/docfragment/19875390//   \n",
       "2  https://indiankanoon.org/docfragment/189088157//   \n",
       "3   https://indiankanoon.org/docfragment/52555161//   \n",
       "4  https://indiankanoon.org/docfragment/139103740//   \n",
       "\n",
       "                                        Case Details  \n",
       "0  Take notes as you read a judgment using our  V...  \n",
       "1  Take notes as you read a judgment using our  V...  \n",
       "2  Take notes as you read a judgment using our  V...  \n",
       "3  Take notes as you read a judgment using our  V...  \n",
       "4  Take notes as you read a judgment using our  V...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length=2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc=nlp(text)\n",
    "    li=[]\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        else:\n",
    "         li.append(token.lemma_)\n",
    "    return \" \".join(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5432/5432 [1:18:31<00:00,  1.15it/s]  \n"
     ]
    }
   ],
   "source": [
    "df[\"new_text\"]=df[\"Case Details\"].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(text):\n",
    "    doc=nlp(text)\n",
    "    return doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5432 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5432/5432 [1:22:49<00:00,  1.09it/s]     \n"
     ]
    }
   ],
   "source": [
    "df[\"text_word_embedded\"]=df[\"new_text\"].progress_apply(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./word_embeddings_all_states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Python312\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering, MeanShift\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'text_word_embedded' is your word embedding matrix\n",
    "# text_word_embedded = ...  # Load or define your word embeddings here\n",
    "X = np.array(list(df['text_word_embedded']))\n",
    "# 1. Data Scaling and PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA with 50 components (adjustable)\n",
    "pca = PCA(n_components=50)  \n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 2. Clustering Models\n",
    "clustering_models = {\n",
    "    'KMeans': KMeans(n_clusters=2, random_state=42),\n",
    "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5),\n",
    "    'Agglomerative': AgglomerativeClustering(n_clusters=2),\n",
    "    'SpectralClustering': SpectralClustering(n_clusters=2, affinity='nearest_neighbors', random_state=42),\n",
    "    'GaussianMixture': GaussianMixture(n_components=2, random_state=42),\n",
    "    'MeanShift': MeanShift()\n",
    "}\n",
    "\n",
    "# 3. Fit Models and Collect Cluster Labels\n",
    "cluster_labels = pd.DataFrame()\n",
    "\n",
    "for name, model in clustering_models.items():\n",
    "    if name == 'DBSCAN':\n",
    "        model.fit(X_scaled)\n",
    "        labels = model.labels_\n",
    "    else:\n",
    "        labels = model.fit_predict(X_scaled)\n",
    "    cluster_labels[name] = labels\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 4. Handle Different Number of Clusters (for DBSCAN noise points)\n",
    "for name in cluster_labels.columns:\n",
    "    if name == 'DBSCAN':\n",
    "        max_label = cluster_labels[name].max()\n",
    "        cluster_labels[name] = cluster_labels[name].apply(lambda x: x if x != -1 else max_label + 1)\n",
    "\n",
    "# 5. Ensemble Clustering via Majority Voting\n",
    "ensemble_labels = cluster_labels.mode(axis=1)[0]\n",
    "df['ensemble_cluster'] = ensemble_labels\n",
    "\n",
    "# 6. Evaluate Clustering Quality (Silhouette Score)\n",
    "sil_scores = {}\n",
    "for name in clustering_models.keys():\n",
    "    if name == 'DBSCAN' and -1 in cluster_labels[name].unique():\n",
    "        if len(set(cluster_labels[name])) > 1:\n",
    "            sil = silhouette_score(X_scaled, cluster_labels[name])\n",
    "            sil_scores[name] = sil\n",
    "    else:\n",
    "        sil = silhouette_score(X_scaled, cluster_labels[name])\n",
    "        sil_scores[name] = sil\n",
    "\n",
    "print(\"Silhouette Scores for Clustering Models:\")\n",
    "for name, score in sil_scores.items():\n",
    "    print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "# Identify the best model based on silhouette score\n",
    "best_model_name = max(sil_scores, key=sil_scores.get)\n",
    "best_sil_score = sil_scores[best_model_name]\n",
    "\n",
    "# 7. Calculate Support and Confidence\n",
    "# Support = Proportion of data points in each cluster\n",
    "# Confidence = Ratio of points in the cluster to total points\n",
    "\n",
    "cluster_counts = df['ensemble_cluster'].value_counts()\n",
    "support = cluster_counts / len(df)\n",
    "confidence = cluster_counts / cluster_counts.sum()\n",
    "\n",
    "print(\"\\nSupport for each cluster:\")\n",
    "print(support)\n",
    "\n",
    "print(\"\\nConfidence for each cluster:\")\n",
    "print(confidence)\n",
    "\n",
    "# 8. Visualize Cluster Distribution\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(df['ensemble_cluster'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['ensemble_cluster'], cmap='viridis', alpha=0.6)\n",
    "plt.title('Ensemble Clustering Results (PCA Reduced)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "plt.show()\n",
    "\n",
    "# 9. Identify Potential Fraudulent Clusters\n",
    "threshold = 20  # Define a threshold for small clusters\n",
    "fraud_clusters = cluster_counts[cluster_counts < threshold].index.tolist()\n",
    "df['is_potential_fraud'] = df['ensemble_cluster'].apply(lambda x: 1 if x in fraud_clusters else 0)\n",
    "\n",
    "# 10. Anomaly Detection with Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "df['anomaly_score'] = iso_forest.fit_predict(X_scaled)\n",
    "df['is_anomaly'] = df['anomaly_score'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# Combine Cluster-Based and Anomaly Detection Results\n",
    "df['final_fraud_flag'] = df['is_potential_fraud'] | df['is_anomaly']\n",
    "\n",
    "# Final Fraud Cases\n",
    "final_frauds = df[df['final_fraud_flag'] == 1]\n",
    "print(f\"\\nFinal Potential Fraudulent Cases ({len(final_frauds)}):\")\n",
    "print(final_frauds[['Case Details', 'ensemble_cluster', 'is_anomaly']])\n",
    "\n",
    "# 11. Print and Save Best Model\n",
    "print(f\"THE BEST MODEL IS: {best_model_name} WITH SILHOUETTE SCORE: {best_sil_score:.4f}\".upper())\n",
    "\n",
    "\n",
    "# Save the best model's results\n",
    "# df['best_model_cluster'] = cluster_labels[best_model_name]\n",
    "# df.to_csv(f\"best_model_{best_model_name}_results.csv\", index=False)\n",
    "# print(f\"Results saved as 'best_model_{best_model_name}_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
